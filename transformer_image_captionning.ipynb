{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "ak4cYMCy-UBv"
      ],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyMQPqvik/q6M5Lzmjb9Sr6W",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d7682996df94d659e1f4733643f01e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac0d6434d3a64897aae749b1d68be55b",
              "IPY_MODEL_5f6cd58aaf9b480fab4c11097e413493",
              "IPY_MODEL_04c3465f468a46e19b1331cab591ec9e"
            ],
            "layout": "IPY_MODEL_b7b84ae30851443e94d301eff25f76e3"
          }
        },
        "ac0d6434d3a64897aae749b1d68be55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_286675a74e8e4a54b11b596bffe83cbb",
            "placeholder": "​",
            "style": "IPY_MODEL_20301e1d5ce3470797d779175fb89395",
            "value": "100%"
          }
        },
        "5f6cd58aaf9b480fab4c11097e413493": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1c7160020c9416f9194aec03befe298",
            "max": 423,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d54980dc6e04499f8e6efc4abb5cd528",
            "value": 423
          }
        },
        "04c3465f468a46e19b1331cab591ec9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53000d9c422545529b8e2cfdad292275",
            "placeholder": "​",
            "style": "IPY_MODEL_63266e9860814fcbba95fbe0de148291",
            "value": " 423/423 [28:04&lt;00:00,  2.62s/it]"
          }
        },
        "b7b84ae30851443e94d301eff25f76e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "286675a74e8e4a54b11b596bffe83cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "20301e1d5ce3470797d779175fb89395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1c7160020c9416f9194aec03befe298": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d54980dc6e04499f8e6efc4abb5cd528": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "53000d9c422545529b8e2cfdad292275": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63266e9860814fcbba95fbe0de148291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4990e5d74e7d45bab62efed2184eb8a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1f5f4f296b14d7d976f4397b408d716",
              "IPY_MODEL_21bb8a2b0a7044798d2bd11b869c1e50",
              "IPY_MODEL_940f525ee4684ce4b994ca7e879b266b"
            ],
            "layout": "IPY_MODEL_3b8a8e91ff714290bde081d4543d711a"
          }
        },
        "b1f5f4f296b14d7d976f4397b408d716": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1a33f20f3d146b8a744218ab65e9e75",
            "placeholder": "​",
            "style": "IPY_MODEL_019b68ee5a334c019f730c81bd04612c",
            "value": "100%"
          }
        },
        "21bb8a2b0a7044798d2bd11b869c1e50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a875ccec56434faf8fc61b5259b2dcb0",
            "max": 75,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04b2d42c5860400392ac8e90b5bfeacc",
            "value": 75
          }
        },
        "940f525ee4684ce4b994ca7e879b266b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d08983bbb2904cdc9c35ccccaab28537",
            "placeholder": "​",
            "style": "IPY_MODEL_5c69944a2ce943cd9c2e4020a78a202b",
            "value": " 75/75 [04:35&lt;00:00,  3.04s/it]"
          }
        },
        "3b8a8e91ff714290bde081d4543d711a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1a33f20f3d146b8a744218ab65e9e75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "019b68ee5a334c019f730c81bd04612c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a875ccec56434faf8fc61b5259b2dcb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04b2d42c5860400392ac8e90b5bfeacc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d08983bbb2904cdc9c35ccccaab28537": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c69944a2ce943cd9c2e4020a78a202b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/spaarky/portfolio/blob/main/image_captionning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf==3.20"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 636
        },
        "collapsed": true,
        "id": "oFC3EkrWxpXR",
        "outputId": "67a5604b-743a-4902-c9f7-327dfbcdad47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting protobuf==3.20\n",
            "  Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (698 bytes)\n",
            "Downloading protobuf-3.20.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: protobuf\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 3.20.3\n",
            "    Uninstalling protobuf-3.20.3:\n",
            "      Successfully uninstalled protobuf-3.20.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-ai-generativelanguage 0.6.6 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-api-core 2.19.2 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-aiplatform 1.66.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.26.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-datastore 2.19.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-firestore 2.16.1 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.19.5, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-pubsub 2.23.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow 2.17.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3, but you have protobuf 3.20.0 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.20.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed protobuf-3.20.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "b4b5f20c931249ab897fe9f60cc60b67"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUE3fvG19Q37",
        "outputId": "72d78ffc-07c1-474f-cf20-033d2411e846"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Installs and Imports\n",
        "Restart to install protobuf and then execute this section. <br>\n",
        "Protobuf >= 3.20 is required for tensorflow-text"
      ],
      "metadata": {
        "id": "ak4cYMCy-UBv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "g6zJDUlcxQWa",
        "outputId": "5fd71bc7-a8c3-4cff-8846-69c919655927"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m80.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 kB\u001b[0m \u001b[31m34.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m101.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires protobuf<5,>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-aiplatform 1.66.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-connection 1.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigquery-storage 2.26.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-bigtable 2.26.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-functions 1.16.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-iam 2.15.2 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-language 2.13.4 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-pubsub 2.23.1 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-resource-manager 1.12.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "google-cloud-translate 3.15.5 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "googleapis-common-protos 1.65.0 requires protobuf!=3.20.0,!=3.20.1,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "grpc-google-iam-v1 0.13.1 requires protobuf!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.2, but you have protobuf 3.19.6 which is incompatible.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow-datasets 4.9.6 requires protobuf>=3.20, but you have protobuf 3.19.6 which is incompatible.\n",
            "tensorflow-metadata 1.15.0 requires protobuf<4.21,>=3.20.3; python_version < \"3.11\", but you have protobuf 3.19.6 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pandas-gbq 0.23.1 requires google-auth-oauthlib>=0.7.0, but you have google-auth-oauthlib 0.4.6 which is incompatible.\n",
            "tensorflow 2.11.1 requires protobuf<3.20,>=3.9.2, but you have protobuf 3.20.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q 'tensorflow-text==2.11.*'\n",
        "!pip install -q tensorflow_datasets\n",
        "!pip install -q einops"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os, collections, re, einops, pathlib, string, time\n",
        "from tqdm.auto import tqdm\n",
        "from PIL import Image\n",
        "import nltk\n",
        "from nltk.util import ngrams\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_text as tf_text\n",
        "import tensorflow_datasets as tfds\n",
        "import random as rd"
      ],
      "metadata": {
        "id": "hHnKeONkyKdG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "tf.get_logger().setLevel('ERROR')\n",
        "\n",
        "nltk.download('punkt')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWqSEVjdyYD0",
        "outputId": "9647a394-c50b-437c-ea92-9928f27899c6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Get and process data, create dataset and functions\n"
      ],
      "metadata": {
        "id": "K_BMl6wW-hHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(path='/content/drive/MyDrive/kaggle_dataset/flickr30k', ratio: float=0.85):\n",
        "    path = pathlib.Path(path)\n",
        "\n",
        "    # Read the cleaned file and parse lines into (image, caption) tuples\n",
        "    captions = (path/'cleaned_captions.txt').read_text().splitlines()\n",
        "    captions = [cap.split(',') for cap in captions]\n",
        "    captions = [tuple(item) for item in captions]\n",
        "\n",
        "    cap_dict = collections.defaultdict(list)\n",
        "    for img_path, cap in captions:\n",
        "        cap_dict[img_path].append(cap)\n",
        "\n",
        "    # Retrieve the list of unique images\n",
        "    unique_images = list(cap_dict.keys())\n",
        "\n",
        "    # Shuffle the list of unique images\n",
        "    rd.shuffle(unique_images)\n",
        "\n",
        "    # Calculate split index based on the ratio\n",
        "    split_index = int(len(unique_images) * ratio)\n",
        "\n",
        "    # Distribute images into train and test sets\n",
        "    train_images_path = unique_images[:split_index]\n",
        "    test_images_path = unique_images[split_index:]\n",
        "\n",
        "\n",
        "    train_caps = [(str(path/'Images'/img_path), cap_dict[img_path]) for img_path in train_images_path]\n",
        "    test_caps = [(str(path/'Images'/img_path), cap_dict[img_path]) for img_path in test_images_path]\n",
        "\n",
        "    # Create TensorFlow datasets\n",
        "    train_raw = tf.data.experimental.from_list(train_caps)\n",
        "    test_raw = tf.data.experimental.from_list(test_caps)\n",
        "\n",
        "    return train_raw, test_raw"
      ],
      "metadata": {
        "id": "WDMzfTVq0wrf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_raw, test_raw = get_dataset()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WzRijUgm87pO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set input shape for images\n",
        "image_shape = (224, 224, 3)\n",
        "# Use MobileNet to have prepocessing\n",
        "feature_extractor = tf.keras.applications.MobileNetV3Small(input_shape=image_shape, include_preprocessing=True, include_top=False)\n",
        "# Disable training for the feature extractor\n",
        "feature_extractor.trainable = False"
      ],
      "metadata": {
        "id": "BqN7VEWaLZf9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d841e4cb-879e-42b9-e26f-e14b3c99cb4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "4334752/4334752 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_image(path):\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.io.decode_jpeg(img, channels = 3)\n",
        "    img = tf.image.resize(img, image_shape[:-1])\n",
        "    return img"
      ],
      "metadata": {
        "id": "CDpQk8PwRSq9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def standardize(text):\n",
        "    # Lower all characters in text\n",
        "    text = tf.strings.lower(text)\n",
        "\n",
        "    # Replace all ponctuation\n",
        "    text = tf.strings.regex_replace(text, f'[{re.escape(string.punctuation)}]', '')\n",
        "\n",
        "    # Add start and end balise\n",
        "    text = tf.strings.join(['[START]',text,'[END]'], separator=' ')\n",
        "\n",
        "    return text"
      ],
      "metadata": {
        "id": "qfatuOQPSNU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 5000\n",
        "vectorizer = tf.keras.layers.TextVectorization(max_tokens=vocab_size,\n",
        "                                            standardize=standardize,\n",
        "                                            ragged=True)\n",
        "vectorizer.adapt(train_raw.map(lambda img_path, caption: caption).unbatch().batch(1024))"
      ],
      "metadata": {
        "id": "bdGn-eTFTXLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_to_id_vectorizer = tf.keras.layers.StringLookup(vocabulary=vectorizer.get_vocabulary(), mask_token='')\n",
        "id_to_text_vectorizer = tf.keras.layers.StringLookup(vocabulary=vectorizer.get_vocabulary(), mask_token='', invert=True)"
      ],
      "metadata": {
        "id": "epbMJRU9UAxH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def id_to_text(token_ids, reserved_tokens = ['', '[UNK]', '[START]', '[END]']):\n",
        "    words = id_to_text_vectorizer(token_ids)\n",
        "    bad_tokens = [re.escape(tok) for tok in reserved_tokens if tok != '[UNK]']\n",
        "    bad_tokens_re = '|'.join(bad_tokens)\n",
        "    bad_mask = tf.strings.regex_full_match(words, bad_tokens_re)\n",
        "    words = tf.ragged.boolean_mask(words, ~bad_mask)\n",
        "\n",
        "    return tf.strings.reduce_join(words, axis = -1, separator = ' ')"
      ],
      "metadata": {
        "id": "wyhBVxFJUp0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def serialize_data(images, captions):\n",
        "    captions_shape = einops.parse_shape(captions, 'b c')\n",
        "    captions = einops.rearrange(captions, 'b c -> (b c)')\n",
        "    images = einops.repeat(images, 'b ...  -> (b c) ...', c = captions_shape['c'])\n",
        "    return images, captions"
      ],
      "metadata": {
        "id": "vJtWDz0jVu-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_batch(img, cap):\n",
        "    cap_tokenized = vectorizer(cap)\n",
        "    cap_tokenized_in = cap_tokenized[:, :-1]\n",
        "    cap_tokenized_out = cap_tokenized[:, 1:]\n",
        "\n",
        "    return (img, cap_tokenized_in.to_tensor()), cap_tokenized_out.to_tensor()"
      ],
      "metadata": {
        "id": "ShRh51TMX4yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_dataset(raw_ds, file_path, image_feature_extractor, vectorizer, shards = 20, batch_size = 64):\n",
        "    raw_ds = (raw_ds\n",
        "              .map(lambda img_path, cap: (load_image(img_path), cap), tf.data.AUTOTUNE)\n",
        "              .batch(batch_size))\n",
        "\n",
        "    def gen():\n",
        "        for (img, cap) in tqdm(raw_ds):\n",
        "            img_features = image_feature_extractor(img)\n",
        "            img_features, cap = serialize_data(img_features, cap)\n",
        "\n",
        "            yield img_features, cap\n",
        "\n",
        "    ds = tf.data.Dataset.from_generator(gen,\n",
        "                                        output_signature = (\n",
        "                                            tf.TensorSpec(shape=image_feature_extractor.output_shape),\n",
        "                                            tf.TensorSpec(shape=(None,), dtype=tf.string)\n",
        "                                        ))\n",
        "\n",
        "    ds = (ds\n",
        "          .map(prepare_batch, tf.data.AUTOTUNE)\n",
        "          .unbatch()\n",
        "          .shuffle(1000))\n",
        "\n",
        "    def shard_func(i, data):\n",
        "        return i % shards\n",
        "\n",
        "    ds.enumerate().save(file_path, shard_func = shard_func)"
      ],
      "metadata": {
        "id": "bg8uXnV_YeGj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "save_dataset(train_raw, 'train_cache', feature_extractor, vectorizer)\n",
        "save_dataset(test_raw, 'test_cache', feature_extractor, vectorizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "6d7682996df94d659e1f4733643f01e0",
            "ac0d6434d3a64897aae749b1d68be55b",
            "5f6cd58aaf9b480fab4c11097e413493",
            "04c3465f468a46e19b1331cab591ec9e",
            "b7b84ae30851443e94d301eff25f76e3",
            "286675a74e8e4a54b11b596bffe83cbb",
            "20301e1d5ce3470797d779175fb89395",
            "b1c7160020c9416f9194aec03befe298",
            "d54980dc6e04499f8e6efc4abb5cd528",
            "53000d9c422545529b8e2cfdad292275",
            "63266e9860814fcbba95fbe0de148291",
            "4990e5d74e7d45bab62efed2184eb8a0",
            "b1f5f4f296b14d7d976f4397b408d716",
            "21bb8a2b0a7044798d2bd11b869c1e50",
            "940f525ee4684ce4b994ca7e879b266b",
            "3b8a8e91ff714290bde081d4543d711a",
            "f1a33f20f3d146b8a744218ab65e9e75",
            "019b68ee5a334c019f730c81bd04612c",
            "a875ccec56434faf8fc61b5259b2dcb0",
            "04b2d42c5860400392ac8e90b5bfeacc",
            "d08983bbb2904cdc9c35ccccaab28537",
            "5c69944a2ce943cd9c2e4020a78a202b"
          ]
        },
        "id": "_dU89a2yaG-4",
        "outputId": "f38f7d24-2589-4136-d0e3-70bd8681883a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/423 [00:08<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6d7682996df94d659e1f4733643f01e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/75 [00:01<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4990e5d74e7d45bab62efed2184eb8a0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 11min 39s, sys: 42.6 s, total: 12min 21s\n",
            "Wall time: 32min 41s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dataset(file_path, batch_size = 64, cycle_length = 2):\n",
        "    def reader_func(ds):\n",
        "        ds = ds.shuffle(1000)\n",
        "        return ds.interleave(lambda x: x, cycle_length = cycle_length)\n",
        "\n",
        "    def drop_index(i, x):\n",
        "        return x\n",
        "\n",
        "    ds = tf.data.Dataset.load(file_path, reader_func = reader_func)\n",
        "\n",
        "    ds = (ds\n",
        "          .map(drop_index)\n",
        "          .shuffle(1000)\n",
        "          .padded_batch(batch_size)\n",
        "          .prefetch(tf.data.AUTOTUNE))\n",
        "    return ds"
      ],
      "metadata": {
        "id": "4BkeR7s6cTz3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_ds = load_dataset('train_cache', batch_size)\n",
        "test_ds = load_dataset('test_cache', batch_size)"
      ],
      "metadata": {
        "id": "vbZo6TQYdIRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Model"
      ],
      "metadata": {
        "id": "TIa-VwMPWJX1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def positional_encoding(length, depth):\n",
        "    pos = tf.cast(tf.range(length)[:, tf.newaxis], tf.float32)\n",
        "    dep = tf.cast(tf.range(depth)[tf.newaxis, :], tf.float32)\n",
        "    dep = ((dep // 2)*2)/tf.cast(depth, tf.float32)\n",
        "\n",
        "    angle_rates = 1 / (10000**dep)\n",
        "    angle_rads = pos*angle_rates\n",
        "\n",
        "    out = tf.Variable(tf.zeros((length, depth)))\n",
        "    out[:, 0::2].assign(tf.math.sin(angle_rads[:, 0::2]))\n",
        "    out[:, 1::2].assign(tf.math.cos(angle_rads[:, 1::2]))\n",
        "\n",
        "    return out[tf.newaxis, ...]"
      ],
      "metadata": {
        "id": "KI7R92u4WK9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEmbedding(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, d_model):\n",
        "        super().__init__()\n",
        "        self.d_model = d_model\n",
        "        self.embedding = tf.keras.layers.Embedding(vocab_size, d_model, mask_zero = True)\n",
        "        self.pos_enc = positional_encoding(length = 2048, depth = d_model)\n",
        "\n",
        "    def compute_mask(self, *args, **kwargs):\n",
        "        return self.embedding.compute_mask(*args, **kwargs)\n",
        "\n",
        "    def call(self, x):\n",
        "        length = tf.shape(x)[1]\n",
        "        x_emb = self.embedding(x)\n",
        "        x_pos_enc = self.pos_enc[:, :length, :]\n",
        "\n",
        "        x_emb *= tf.cast(self.d_model, tf.float32)\n",
        "        x_emb += x_pos_enc\n",
        "\n",
        "        return x_emb"
      ],
      "metadata": {
        "id": "AwB6RXEqYBKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BaseAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(**kwargs)\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()"
      ],
      "metadata": {
        "id": "ev_evuyuZTXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CausalAttention(BaseAttention):\n",
        "    def call(self, x):\n",
        "        attn_output = self.mha(query = x, key = x, value = x, use_causal_mask = True)\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "-kb7ga7WZyRc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(BaseAttention):\n",
        "    def call(self, ctx, x):\n",
        "        attn_out, attn_scores = self.mha(query = x, key = ctx, value = ctx, return_attention_scores = True)\n",
        "\n",
        "        self.last_attention_scores = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_out])\n",
        "        x = self.layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "FXImdTG1aK8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForward(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.seq = tf.keras.Sequential([\n",
        "            tf.keras.layers.Dense(d_ff, activation='relu'),\n",
        "            tf.keras.layers.Dense(d_model),\n",
        "            tf.keras.layers.Dropout(rate=dropout)\n",
        "        ])\n",
        "\n",
        "        self.add = tf.keras.layers.Add()\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "\n",
        "    def call(self, x):\n",
        "        x = self.add([x, self.seq(x)])\n",
        "        x = self.layernorm(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "i0CoyYxOao9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, d_ff, num_heads, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.causal_attention = CausalAttention(num_heads=num_heads,\n",
        "                                                key_dim=d_model,\n",
        "                                                dropout=dropout)\n",
        "        self.cross_attention = CrossAttention(num_heads=num_heads,\n",
        "                                              key_dim=d_model,\n",
        "                                              dropout=dropout)\n",
        "        self.ffn = FeedForward(d_model=d_model,\n",
        "                               d_ff=d_ff,\n",
        "                               dropout=dropout)\n",
        "        self.last_attention_scores = None\n",
        "\n",
        "    def call(self, ctx, x):\n",
        "        x = self.causal_attention(x)\n",
        "        x = self.cross_attention(ctx=ctx, x=x)\n",
        "        x = self.ffn(x)\n",
        "\n",
        "        self.last_attention_scores = self.cross_attention.last_attention_scores\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "JjlA7B7Zbbu9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class OutputLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab, bad_tokens=('', '[UNK]', '[START]')):\n",
        "        super().__init__()\n",
        "        self.vocab = vocab\n",
        "        self.bad_tokens = bad_tokens\n",
        "        self.bias = 0\n",
        "        self.layerdense = tf.keras.layers.Dense(len(vocab), activation=tf.nn.log_softmax)\n",
        "\n",
        "    def adapt(self, cap_ds):\n",
        "        word_idx = {word: idx for idx, word in enumerate(self.vocab)}\n",
        "        counts = collections.Counter()\n",
        "        for tokens in cap_ds:\n",
        "            counts.update(tokens.numpy().flatten())\n",
        "\n",
        "        counts_arr = np.zeros((len(self.vocab), ))\n",
        "        for token_id, count in counts.items():\n",
        "            counts_arr[token_id] = count\n",
        "\n",
        "        bad_indices = np.array([word_idx[word] for word in self.bad_tokens])\n",
        "        counts_arr[bad_indices] = 0\n",
        "\n",
        "        counts_prob = counts_arr / counts_arr.sum()\n",
        "        counts_prob[counts_arr == 0] = 1\n",
        "        log_p = np.log(counts_prob)\n",
        "\n",
        "        entropy = (-counts_prob*log_p).sum()\n",
        "\n",
        "        print(f'uniform_entropy : {np.log(len(self.vocab))}')\n",
        "        print(f'curr_entropy : {entropy}')\n",
        "        log_p[counts_arr == 0] = -1e9\n",
        "\n",
        "        self.bias = log_p[tf.newaxis, tf.newaxis, :]\n",
        "\n",
        "    def call(self, x):\n",
        "        return self.layerdense(x) + self.bias"
      ],
      "metadata": {
        "id": "0rSXcvPXcsku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, num_heads, d_model, d_ff, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.positional_embedding = PositionalEmbedding(vocab_size, d_model)\n",
        "        self.decoder_layers = [DecoderLayer(d_model, d_ff, num_heads, dropout) for _ in range(num_layers)]\n",
        "        self.last_attention_scores = None\n",
        "\n",
        "    def call(self, ctx, x):\n",
        "        x = self.positional_embedding(x)\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.decoder_layers[i](ctx = ctx, x = x)\n",
        "\n",
        "        self.last_attention_scores = self.decoder_layers[-1].last_attention_scores\n",
        "        return x"
      ],
      "metadata": {
        "id": "oEbod8cIhMqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Captioner(tf.keras.Model):\n",
        "    def __init__(self, vectorizer, feature_extractor, output_layer, num_layers, num_heads, d_model, d_ff, pred_max_len =  50, dropout = 0.1):\n",
        "        super().__init__()\n",
        "        self.feature_extractor = feature_extractor\n",
        "        self.vectorizer = vectorizer\n",
        "        self.output_layer = output_layer\n",
        "        self.decoder = Decoder(num_layers, num_heads, d_model, d_ff, dropout)\n",
        "        self.max_len = pred_max_len\n",
        "        self.vocab = self.vectorizer.get_vocabulary()\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, cap = inputs\n",
        "        if context.shape[-1] == 3:\n",
        "            context = self.feature_extractor(context)\n",
        "        context = einops.rearrange(context, 'b h w c -> b (h w) c')\n",
        "\n",
        "        if cap.dtype == tf.string:\n",
        "            cap = self.vectorizer([cap])\n",
        "\n",
        "\n",
        "        x = self.decoder(context = context, x = cap)\n",
        "        x = self.output_layer(x)\n",
        "        return x\n",
        "\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun"
      ],
      "metadata": {
        "id": "F2FeP8Slieb0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Training"
      ],
      "metadata": {
        "id": "cUJmPZUTlZns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@Captioner.add_method\n",
        "def generate_text(self, img, temperature = 0.5):\n",
        "    if img.shape[-1] == 3:\n",
        "        img = self.feature_extractor(img)\n",
        "    start_token = text_to_id_vectorizer([['[START]']])\n",
        "\n",
        "    start_idx = self.vocab.index('[START]')\n",
        "    end_idx = self.vocab.index('[END]')\n",
        "\n",
        "    for i in range(self.max_len):\n",
        "        preds = self((img, start_token))\n",
        "        preds = preds[:, -1, :]\n",
        "        if temperature == 0.0:\n",
        "            pred_idx = tf.argmax(preds, axis = -1)[:, tf.newaxis]\n",
        "        else:\n",
        "            preds /= temperature\n",
        "            pred_idx = tf.random.categorical(preds, num_samples = 1)\n",
        "\n",
        "        start_token = tf.concat([start_token, pred_idx], axis = -1)\n",
        "\n",
        "        if pred_idx[0][0] == end_idx:\n",
        "            break\n",
        "\n",
        "    return id_to_text(start_token).numpy()[0].decode('utf-8')"
      ],
      "metadata": {
        "id": "WA6kFHFflbDR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def brevity_penalty(can, ref):\n",
        "    can_tokens = nltk.word_tokenize(can)\n",
        "    ref_tokens = nltk.word_tokenize(ref)\n",
        "    if len(can_tokens) == 0:\n",
        "        return 0.0\n",
        "    return min(1, np.exp(1 - (len(ref_tokens) / len(can_tokens))))\n",
        "\n",
        "def precision(can, ref, n):\n",
        "    can_n = collections.Counter(ngrams(nltk.word_tokenize(can), n))\n",
        "    ref_n = collections.Counter(ngrams(nltk.word_tokenize(ref), n))\n",
        "    total = sum(can_n.values())\n",
        "\n",
        "    if total == 0:\n",
        "        return 0\n",
        "\n",
        "    for n_g in can_n:\n",
        "        if n_g in ref_n:\n",
        "            can_n[n_g] = min(can_n[n_g], ref_n[n_g])\n",
        "        else:\n",
        "            can_n[n_g] = 0\n",
        "    return sum(can_n.values()) / total\n",
        "\n",
        "def bleu_score(can , ref, n_gram_range = 2):\n",
        "    precisions = []\n",
        "    b_p = brevity_penalty(can, ref)\n",
        "    for n in range(1, n_gram_range + 1):\n",
        "        precisions.append(precision(can, ref, n))\n",
        "    precisions = np.array(precisions)\n",
        "\n",
        "    if 0 in precisions:\n",
        "        # As log of 0 will be -inf and exp of that will be back to 0 with warning.\n",
        "        return 0.0\n",
        "    return b_p * np.exp(np.log(precisions).mean())\n",
        "\n",
        "def recall(can, ref, n):\n",
        "    can_n = collections.Counter(ngrams(nltk.word_tokenize(can), n))\n",
        "    ref_n = collections.Counter(ngrams(nltk.word_tokenize(ref), n))\n",
        "    total = sum(ref_n.values())\n",
        "\n",
        "    if total == 0:\n",
        "        return 0\n",
        "\n",
        "    for n_g in ref_n:\n",
        "        if n_g in can_n:\n",
        "            ref_n[n_g] = min(can_n[n_g], ref_n[n_g])\n",
        "        else:\n",
        "            ref_n[n_g] = 0\n",
        "    return sum(ref_n.values()) / total\n",
        "\n",
        "def rouge_score(can , ref, n_gram_range = 2):\n",
        "    recalls = []\n",
        "    b_p = brevity_penalty(can, ref)\n",
        "    for n in range(1, n_gram_range + 1):\n",
        "        recalls.append(recall(can, ref, n))\n",
        "    recalls = np.array(recalls)\n",
        "\n",
        "    if 0 in recalls:\n",
        "        # As log of 0 will be -inf and exp of that will be back to 0 with warning.\n",
        "        return 0.0\n",
        "    return b_p * np.exp(np.log(recalls).mean())"
      ],
      "metadata": {
        "id": "iN58poRRoBnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(labels, preds):\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits = True, reduction = 'none')\n",
        "    loss = tf.cast(loss_fn(labels, preds), tf.float32)\n",
        "    mask = ((labels != 0) & (loss < 1e8))\n",
        "    mask = tf.cast(mask, tf.float32)\n",
        "    loss *= mask\n",
        "    return tf.math.reduce_sum(loss) / tf.math.reduce_sum(mask)\n",
        "\n",
        "def masked_accuracy(labels, preds):\n",
        "    preds = tf.cast(tf.argmax(preds, axis = -1), tf.float32)\n",
        "    labels = tf.cast(labels, tf.float32)\n",
        "    mask = tf.cast(labels != 0, tf.float32)\n",
        "    acc = tf.cast(preds == labels, tf.float32)\n",
        "    acc *= mask\n",
        "    return tf.math.reduce_sum(acc) / tf.math.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "8vUemEBVoKOo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Captioner.add_method\n",
        "def f_score(self, can, refs, n_gram_range = 1):\n",
        "    b_scores = [bleu_score(can, ref, n_gram_range) for ref in refs]\n",
        "    r_scores = [rouge_score(can, ref, n_gram_range)  for ref in refs]\n",
        "    f_vals = []\n",
        "    for b_score, r_score in zip(b_scores, r_scores):\n",
        "        if b_score + r_score == 0:\n",
        "            return 0\n",
        "        f_vals.append((2*b_score*r_score) / (b_score + r_score))\n",
        "\n",
        "    return max(f_vals)"
      ],
      "metadata": {
        "id": "mdlFwyCeoF9f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GenerateText(tf.keras.callbacks.Callback):\n",
        "    def __init__(self, img = img):\n",
        "        self.image = img[tf.newaxis, ...]\n",
        "        self.caps = caps\n",
        "\n",
        "    def on_epoch_end(self, epochs = None, logs = None):\n",
        "        print('\\n')\n",
        "        for temp in (0, 0.5, 1):\n",
        "            gen_text = self.model.generate_text(self.image)\n",
        "            f_val = self.model.f_score(gen_text, self.caps, n_gram_range = 1)\n",
        "            print(f'Generated_text: {gen_text}, \\t f_score: {f_val}')"
      ],
      "metadata": {
        "id": "OQQRanDEoiRE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate = 0.0001)\n",
        "callbacks = [GenerateText(),\n",
        "             tf.keras.callbacks.EarlyStopping(patience = 6, restore_best_weights = True)]"
      ],
      "metadata": {
        "id": "lXi-UuC6ozmu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "captioner_model.compile(loss = masked_loss, optimizer = optimizer, metrics = [masked_accuracy])"
      ],
      "metadata": {
        "id": "Lhf7gSYBo3o6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = captioner_model.fit(\n",
        "    train_ds.repeat(),\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data = test_ds.repeat(),\n",
        "    validation_steps = 20,\n",
        "    epochs = 150,\n",
        "    callbacks = callbacks\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74tOqFfHo6lS",
        "outputId": "541e34bf-dbd1-4486-f1c5-bd45ca012555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.8483 - masked_accuracy: 0.3197\n",
            "\n",
            "Generated_text: a young boy in a green shirt is walking down the grass, \t f_score: 0.3906838730264372\n",
            "Generated_text: a dog in a red and white dog with a red pants is running through the grass, \t f_score: 0.29411764705882354\n",
            "Generated_text: a girl in a white and white shirt is playing a white dog, \t f_score: 0.41153825717436265\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 3.8483 - masked_accuracy: 0.3197 - val_loss: 3.8325 - val_masked_accuracy: 0.3252\n",
            "Epoch 2/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.8200 - masked_accuracy: 0.3221\n",
            "\n",
            "Generated_text: a dog jumps up to a young boy in a black dog, \t f_score: 0.2608695652173913\n",
            "Generated_text: a dog in a white and a black dog running down a field, \t f_score: 0.24999999999999994\n",
            "Generated_text: a dog is running in a field, \t f_score: 0.1882393740025864\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 3.8200 - masked_accuracy: 0.3221 - val_loss: 3.7634 - val_masked_accuracy: 0.3315\n",
            "Epoch 3/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.8041 - masked_accuracy: 0.3269\n",
            "\n",
            "Generated_text: a small girl is jumping in a ball in the grass, \t f_score: 0.36363636363636376\n",
            "Generated_text: a dog is running on a cellphone, \t f_score: 0.15459210301798523\n",
            "Generated_text: a dog in a white dog is running down a ball on a ground, \t f_score: 0.2857142857142857\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 3.8041 - masked_accuracy: 0.3269 - val_loss: 3.7255 - val_masked_accuracy: 0.3290\n",
            "Epoch 4/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7855 - masked_accuracy: 0.3235\n",
            "\n",
            "Generated_text: a white dog is running on the grass, \t f_score: 0.12130613194252668\n",
            "Generated_text: a dog is running in the grass, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 3.7855 - masked_accuracy: 0.3235 - val_loss: 3.7427 - val_masked_accuracy: 0.3348\n",
            "Epoch 5/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7564 - masked_accuracy: 0.3244\n",
            "\n",
            "Generated_text: two dogs are running through a field, \t f_score: 0.06274645800086213\n",
            "Generated_text: a young boy is running in a ball with a grassy field, \t f_score: 0.3255698941886978\n",
            "Generated_text: a young girl in a white shirt and black and white shirt is jumping in the grass, \t f_score: 0.45161290322580644\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.7564 - masked_accuracy: 0.3244 - val_loss: 3.6755 - val_masked_accuracy: 0.3364\n",
            "Epoch 6/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7243 - masked_accuracy: 0.3273\n",
            "\n",
            "Generated_text: a dog is running through a tree, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog is running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog is playing with a field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 3.7243 - masked_accuracy: 0.3273 - val_loss: 3.6908 - val_masked_accuracy: 0.3337\n",
            "Epoch 7/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.7025 - masked_accuracy: 0.3292\n",
            "\n",
            "Generated_text: a dog with a black and white dog is running through a field, \t f_score: 0.20576912858718135\n",
            "Generated_text: a young girl is jumping to the grass, \t f_score: 0.17176965554218718\n",
            "Generated_text: a dog is running down a field of the grass, \t f_score: 0.2234400153452131\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 3.7025 - masked_accuracy: 0.3292 - val_loss: 3.6959 - val_masked_accuracy: 0.3315\n",
            "Epoch 8/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6878 - masked_accuracy: 0.3314\n",
            "\n",
            "Generated_text: a dog is jumping up in a field, \t f_score: 0.2170387196182017\n",
            "Generated_text: a dog and her dog running in the grass, \t f_score: 0.16014748058336156\n",
            "Generated_text: a young boy in a black dog is running through the grass, \t f_score: 0.3255698941886978\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 3.6878 - masked_accuracy: 0.3314 - val_loss: 3.6262 - val_masked_accuracy: 0.3400\n",
            "Epoch 9/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6852 - masked_accuracy: 0.3307\n",
            "\n",
            "Generated_text: a dog is jumping in the grass, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog runs through a ball in the air, \t f_score: 0.24022122087504233\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.6852 - masked_accuracy: 0.3307 - val_loss: 3.6173 - val_masked_accuracy: 0.3380\n",
            "Epoch 10/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6816 - masked_accuracy: 0.3305\n",
            "\n",
            "Generated_text: a dog play with a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog is running on a field, \t f_score: 0.15459210301798523\n",
            "Generated_text: a dog running through a field, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 3.6816 - masked_accuracy: 0.3305 - val_loss: 3.5580 - val_masked_accuracy: 0.3435\n",
            "Epoch 11/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6523 - masked_accuracy: 0.3322\n",
            "\n",
            "Generated_text: a dog running with a frisbee in a field, \t f_score: 0.24022122087504233\n",
            "Generated_text: a dog jumps over a grassy field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a little girl in a black and black hair is playing in a blue ball, \t f_score: 0.4137931034482759\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 3.6523 - masked_accuracy: 0.3322 - val_loss: 3.5761 - val_masked_accuracy: 0.3403\n",
            "Epoch 12/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6395 - masked_accuracy: 0.3302\n",
            "\n",
            "Generated_text: a dog running through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a young girl is running through a field, \t f_score: 0.214712069427734\n",
            "Generated_text: a dog stands in the grass, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 3.6395 - masked_accuracy: 0.3302 - val_loss: 3.5864 - val_masked_accuracy: 0.3409\n",
            "Epoch 13/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5977 - masked_accuracy: 0.3376\n",
            "\n",
            "Generated_text: a dog is running through a grassy ball, \t f_score: 0.1446924797454678\n",
            "Generated_text: a dog running in a field, \t f_score: 0.1533876030024982\n",
            "Generated_text: a young boy playing with a ball in the grass, \t f_score: 0.2585249765817027\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.5977 - masked_accuracy: 0.3376 - val_loss: 3.5042 - val_masked_accuracy: 0.3479\n",
            "Epoch 14/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5702 - masked_accuracy: 0.3393\n",
            "\n",
            "Generated_text: a dog runs through the grass in the grass, \t f_score: 0.16014748058336156\n",
            "Generated_text: a little boy and white dog running through the grass, \t f_score: 0.14886013692326946\n",
            "Generated_text: a little girl in a white sweater is running through a field, \t f_score: 0.3333333333333333\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 3.5702 - masked_accuracy: 0.3393 - val_loss: 3.5194 - val_masked_accuracy: 0.3460\n",
            "Epoch 15/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.6118 - masked_accuracy: 0.3315\n",
            "\n",
            "Generated_text: two dogs run down the grass, \t f_score: 0\n",
            "Generated_text: a dog running in the grass, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog is running with a field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 3.6118 - masked_accuracy: 0.3315 - val_loss: 3.5223 - val_masked_accuracy: 0.3480\n",
            "Epoch 16/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5815 - masked_accuracy: 0.3377\n",
            "\n",
            "Generated_text: a little girl in a green shirt and white dog running in a field, \t f_score: 0.5\n",
            "Generated_text: a dog is running through the grass, \t f_score: 0.07007227450884616\n",
            "Generated_text: a dog running through the grass, \t f_score: 0.05112920100083274\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 3.5815 - masked_accuracy: 0.3377 - val_loss: 3.5238 - val_masked_accuracy: 0.3488\n",
            "Epoch 17/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5618 - masked_accuracy: 0.3388\n",
            "\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a girl with white dog is playing with a toy, \t f_score: 0.2234400153452131\n",
            "Generated_text: two dogs run on the grass, \t f_score: 0\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 3.5618 - masked_accuracy: 0.3388 - val_loss: 3.4430 - val_masked_accuracy: 0.3503\n",
            "Epoch 18/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5384 - masked_accuracy: 0.3399\n",
            "\n",
            "Generated_text: a dog jumps into a grassy field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a little boy wearing a white shirt and a brown dog runs through a field, \t f_score: 0.2758620689655172\n",
            "Generated_text: a dog runs through a grassy field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 3.5384 - masked_accuracy: 0.3399 - val_loss: 3.4820 - val_masked_accuracy: 0.3442\n",
            "Epoch 19/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5225 - masked_accuracy: 0.3412\n",
            "\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog running along a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a brown dog is running through a park, \t f_score: 0.2170387196182017\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 3.5225 - masked_accuracy: 0.3412 - val_loss: 3.4117 - val_masked_accuracy: 0.3529\n",
            "Epoch 20/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5275 - masked_accuracy: 0.3394\n",
            "\n",
            "Generated_text: a dog with a black dog runs through a field, \t f_score: 0.17234998438780183\n",
            "Generated_text: a little girl in a white dog running through a field, \t f_score: 0.3176002491416565\n",
            "Generated_text: two dogs are playing in the grass, \t f_score: 0\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 3.5275 - masked_accuracy: 0.3394 - val_loss: 3.4542 - val_masked_accuracy: 0.3518\n",
            "Epoch 21/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.5244 - masked_accuracy: 0.3424\n",
            "\n",
            "Generated_text: a dog is playing in the grass, \t f_score: 0.12549291600172427\n",
            "Generated_text: a little boy and a dog running in the grass, \t f_score: 0.2585249765817027\n",
            "Generated_text: a young boy plays on a field in a field, \t f_score: 0.2585249765817027\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.5244 - masked_accuracy: 0.3424 - val_loss: 3.4327 - val_masked_accuracy: 0.3536\n",
            "Epoch 22/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4541 - masked_accuracy: 0.3463\n",
            "\n",
            "Generated_text: a little girl is running through a park, \t f_score: 0.24261226388505333\n",
            "Generated_text: a dog runs in a field, \t f_score: 0.1533876030024982\n",
            "Generated_text: a little girl is running through an orange field, \t f_score: 0.20472323159251127\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.4541 - masked_accuracy: 0.3463 - val_loss: 3.4053 - val_masked_accuracy: 0.3498\n",
            "Epoch 23/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4541 - masked_accuracy: 0.3450\n",
            "\n",
            "Generated_text: a small dog is running on a field, \t f_score: 0.18195919791379003\n",
            "Generated_text: a dog is running through the grass, \t f_score: 0.07007227450884616\n",
            "Generated_text: a dog runs through the grass, \t f_score: 0.05112920100083274\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 3.4541 - masked_accuracy: 0.3450 - val_loss: 3.3874 - val_masked_accuracy: 0.3536\n",
            "Epoch 24/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4449 - masked_accuracy: 0.3462\n",
            "\n",
            "Generated_text: a boy in a field, \t f_score: 0.11294782946707575\n",
            "Generated_text: a young girl is running in a field, \t f_score: 0.2576544833132807\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 3.4449 - masked_accuracy: 0.3462 - val_loss: 3.4009 - val_masked_accuracy: 0.3530\n",
            "Epoch 25/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4237 - masked_accuracy: 0.3498\n",
            "\n",
            "Generated_text: a man is running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a young girl runs through the grass, \t f_score: 0.10510841176326925\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 3.4237 - masked_accuracy: 0.3498 - val_loss: 3.3914 - val_masked_accuracy: 0.3538\n",
            "Epoch 26/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4249 - masked_accuracy: 0.3476\n",
            "\n",
            "Generated_text: a woman in a white shirt is running through the grass, \t f_score: 0.30452015467874954\n",
            "Generated_text: a little girl with a white dog on a grassy field, \t f_score: 0.39700031142707054\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 3.4249 - masked_accuracy: 0.3476 - val_loss: 3.4285 - val_masked_accuracy: 0.3528\n",
            "Epoch 27/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4179 - masked_accuracy: 0.3462\n",
            "\n",
            "Generated_text: a small dog running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a man in a black and white and white dress is running through the grass, \t f_score: 0.3076923076923077\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 3.4179 - masked_accuracy: 0.3462 - val_loss: 3.3434 - val_masked_accuracy: 0.3584\n",
            "Epoch 28/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.4165 - masked_accuracy: 0.3480\n",
            "\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog running through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog is running in a field, \t f_score: 0.1882393740025864\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.4165 - masked_accuracy: 0.3480 - val_loss: 3.3790 - val_masked_accuracy: 0.3572\n",
            "Epoch 29/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3950 - masked_accuracy: 0.3507\n",
            "\n",
            "Generated_text: a dog running along a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog running through the field, \t f_score: 0.05112920100083274\n",
            "Generated_text: a dog running on a grassy field, \t f_score: 0.15459210301798523\n",
            "100/100 [==============================] - 26s 258ms/step - loss: 3.3950 - masked_accuracy: 0.3507 - val_loss: 3.3999 - val_masked_accuracy: 0.3514\n",
            "Epoch 30/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3645 - masked_accuracy: 0.3544\n",
            "\n",
            "Generated_text: a dog is running through a grassy field, \t f_score: 0.1446924797454678\n",
            "Generated_text: a dog is running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog is running on a field, \t f_score: 0.15459210301798523\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.3645 - masked_accuracy: 0.3544 - val_loss: 3.3270 - val_masked_accuracy: 0.3567\n",
            "Epoch 31/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3533 - masked_accuracy: 0.3500\n",
            "\n",
            "Generated_text: a young boy is running through a field, \t f_score: 0.17176965554218718\n",
            "Generated_text: a brown dog is running on a field, \t f_score: 0.18195919791379003\n",
            "Generated_text: a dog is running through a field with a soccer ball in the grass, \t f_score: 0.2857142857142857\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 3.3533 - masked_accuracy: 0.3500 - val_loss: 3.3437 - val_masked_accuracy: 0.3559\n",
            "Epoch 32/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3601 - masked_accuracy: 0.3541\n",
            "\n",
            "Generated_text: a dog runs through the grass while the grass, \t f_score: 0.08007374029168078\n",
            "Generated_text: two dogs are playing in a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 3.3601 - masked_accuracy: 0.3541 - val_loss: 3.3462 - val_masked_accuracy: 0.3612\n",
            "Epoch 33/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3599 - masked_accuracy: 0.3516\n",
            "\n",
            "Generated_text: a dog runs through a grassy field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a young boy in a grassy field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog runs through a tree, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 3.3599 - masked_accuracy: 0.3516 - val_loss: 3.3196 - val_masked_accuracy: 0.3587\n",
            "Epoch 34/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3609 - masked_accuracy: 0.3527\n",
            "\n",
            "Generated_text: two girls playing with a ball in the grass, \t f_score: 0.16014748058336156\n",
            "Generated_text: a little girl is running in a field, \t f_score: 0.24261226388505333\n",
            "Generated_text: a woman is playing in a field, \t f_score: 0.1882393740025864\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.3609 - masked_accuracy: 0.3527 - val_loss: 3.2996 - val_masked_accuracy: 0.3574\n",
            "Epoch 35/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3517 - masked_accuracy: 0.3521\n",
            "\n",
            "Generated_text: a little dog running through the grass, \t f_score: 0.10306140201199016\n",
            "Generated_text: a brown dog running on grass, \t f_score: 0.0817509869269872\n",
            "Generated_text: a dog running through a field, \t f_score: 0.10225840200166549\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 3.3517 - masked_accuracy: 0.3521 - val_loss: 3.3280 - val_masked_accuracy: 0.3624\n",
            "Epoch 36/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3664 - masked_accuracy: 0.3519\n",
            "\n",
            "Generated_text: a little girl is running through the grass, \t f_score: 0.18195919791379003\n",
            "Generated_text: a man in a white shirt is playing with a yellow ball, \t f_score: 0.3255698941886978\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.3664 - masked_accuracy: 0.3519 - val_loss: 3.2955 - val_masked_accuracy: 0.3616\n",
            "Epoch 37/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3246 - masked_accuracy: 0.3563\n",
            "\n",
            "Generated_text: the dog is playing with a stick in its mouth, \t f_score: 0.17234998438780183\n",
            "Generated_text: a little girl is playing on the grass, \t f_score: 0.24261226388505333\n",
            "Generated_text: a dog running through a park, \t f_score: 0.1533876030024982\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.3246 - masked_accuracy: 0.3563 - val_loss: 3.2615 - val_masked_accuracy: 0.3681\n",
            "Epoch 38/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3313 - masked_accuracy: 0.3537\n",
            "\n",
            "Generated_text: a black and white dog running through a field, \t f_score: 0.16014748058336156\n",
            "Generated_text: a dog is running in the grass, \t f_score: 0.12549291600172427\n",
            "Generated_text: two dogs are playing in the grass, \t f_score: 0\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 3.3313 - masked_accuracy: 0.3537 - val_loss: 3.2294 - val_masked_accuracy: 0.3687\n",
            "Epoch 39/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.3130 - masked_accuracy: 0.3578\n",
            "\n",
            "Generated_text: a young boy runs through a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a girl in a red shirt is running on a grassy field, \t f_score: 0.3906838730264372\n",
            "Generated_text: a small dog running in the grass, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.3130 - masked_accuracy: 0.3578 - val_loss: 3.3102 - val_masked_accuracy: 0.3603\n",
            "Epoch 40/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2964 - masked_accuracy: 0.3554\n",
            "\n",
            "Generated_text: a young boy is playing in the grass, \t f_score: 0.17176965554218718\n",
            "Generated_text: a dog runs through a grassy field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog is jumping into a grassy field, \t f_score: 0.1446924797454678\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 3.2964 - masked_accuracy: 0.3554 - val_loss: 3.2525 - val_masked_accuracy: 0.3662\n",
            "Epoch 41/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2852 - masked_accuracy: 0.3574\n",
            "\n",
            "Generated_text: a young girl holds a toy in a tennis ball, \t f_score: 0.2977202738465389\n",
            "Generated_text: a little boy is running on a field, \t f_score: 0.24261226388505333\n",
            "Generated_text: a dog and a little girl in a field with a red ball, \t f_score: 0.3429485476453023\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.2852 - masked_accuracy: 0.3574 - val_loss: 3.2348 - val_masked_accuracy: 0.3689\n",
            "Epoch 42/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2961 - masked_accuracy: 0.3558\n",
            "\n",
            "Generated_text: a dog is running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog runs through the grass, \t f_score: 0.05112920100083274\n",
            "Generated_text: a dog is running across the grass, \t f_score: 0.07007227450884616\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 3.2961 - masked_accuracy: 0.3558 - val_loss: 3.2038 - val_masked_accuracy: 0.3699\n",
            "Epoch 43/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2558 - masked_accuracy: 0.3598\n",
            "\n",
            "Generated_text: a girl running with a stick in the grass, \t f_score: 0.24022122087504233\n",
            "Generated_text: a brown and white dog running through a grassy field, \t f_score: 0.17234998438780183\n",
            "Generated_text: a dog running through the grass with the grass, \t f_score: 0.08007374029168078\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 3.2558 - masked_accuracy: 0.3598 - val_loss: 3.1992 - val_masked_accuracy: 0.3693\n",
            "Epoch 44/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2580 - masked_accuracy: 0.3585\n",
            "\n",
            "Generated_text: the little girl is running in a field, \t f_score: 0.18195919791379003\n",
            "Generated_text: a little girl is running through the grass, \t f_score: 0.18195919791379003\n",
            "Generated_text: a small dog is running through the grass, \t f_score: 0.08588482777109359\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 3.2580 - masked_accuracy: 0.3585 - val_loss: 3.2226 - val_masked_accuracy: 0.3612\n",
            "Epoch 45/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2392 - masked_accuracy: 0.3593\n",
            "\n",
            "Generated_text: a little girl in a black and white dog running through a field, \t f_score: 0.3429485476453023\n",
            "Generated_text: a dog is playing with a frisbee in the grass, \t f_score: 0.2585249765817027\n",
            "Generated_text: a dog running on the grass and running through a field, \t f_score: 0.23820018685624236\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 3.2392 - masked_accuracy: 0.3593 - val_loss: 3.2396 - val_masked_accuracy: 0.3693\n",
            "Epoch 46/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2370 - masked_accuracy: 0.3600\n",
            "\n",
            "Generated_text: a young girl playing with his mouth, \t f_score: 0.10510841176326925\n",
            "Generated_text: a dog runs through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog runs through a grassy field, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 26s 265ms/step - loss: 3.2370 - masked_accuracy: 0.3600 - val_loss: 3.2243 - val_masked_accuracy: 0.3719\n",
            "Epoch 47/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2234 - masked_accuracy: 0.3627\n",
            "\n",
            "Generated_text: a small dog running in a field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a dog running with a frisbee in a field, \t f_score: 0.24022122087504233\n",
            "Generated_text: a little girl in a white shirt and white dog running in a field, \t f_score: 0.5\n",
            "100/100 [==============================] - 28s 280ms/step - loss: 3.2234 - masked_accuracy: 0.3627 - val_loss: 3.2185 - val_masked_accuracy: 0.3699\n",
            "Epoch 48/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2211 - masked_accuracy: 0.3606\n",
            "\n",
            "Generated_text: a young girl in a white shirt and white dog watches, \t f_score: 0.3654241856144994\n",
            "Generated_text: a dog running through a field while another dog is running through a grassy field, \t f_score: 0.20689655172413796\n",
            "Generated_text: a little girl in a yellow shirt is playing in the grass, \t f_score: 0.45579785186417676\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 3.2211 - masked_accuracy: 0.3606 - val_loss: 3.1632 - val_masked_accuracy: 0.3737\n",
            "Epoch 49/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2291 - masked_accuracy: 0.3607\n",
            "\n",
            "Generated_text: a dog runs in a field, \t f_score: 0.1533876030024982\n",
            "Generated_text: a dog running through a field, \t f_score: 0.10225840200166549\n",
            "Generated_text: a little girl in a white shirt is lying on a field, \t f_score: 0.4166666666666667\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.2291 - masked_accuracy: 0.3607 - val_loss: 3.1810 - val_masked_accuracy: 0.3673\n",
            "Epoch 50/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2071 - masked_accuracy: 0.3637\n",
            "\n",
            "Generated_text: two dogs run through the grass, \t f_score: 0\n",
            "Generated_text: a young boy is running in a field, \t f_score: 0.2170387196182017\n",
            "Generated_text: a girl is running through a field, \t f_score: 0.15459210301798523\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 3.2071 - masked_accuracy: 0.3637 - val_loss: 3.1825 - val_masked_accuracy: 0.3741\n",
            "Epoch 51/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2109 - masked_accuracy: 0.3630\n",
            "\n",
            "Generated_text: a little girl in a green field with a brown dog is running on her, \t f_score: 0.3703703703703704\n",
            "Generated_text: a brown dog is running through the grass, \t f_score: 0.08588482777109359\n",
            "Generated_text: a dog runs through the grass, \t f_score: 0.05112920100083274\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.2109 - masked_accuracy: 0.3630 - val_loss: 3.1965 - val_masked_accuracy: 0.3630\n",
            "Epoch 52/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2148 - masked_accuracy: 0.3648\n",
            "\n",
            "Generated_text: a brown dog running through a grassy field, \t f_score: 0.1446924797454678\n",
            "Generated_text: a little girl in a pink shirt is running through a park, \t f_score: 0.45579785186417676\n",
            "Generated_text: a girl in a black and white dog running through a grassy field, \t f_score: 0.3429485476453023\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.2148 - masked_accuracy: 0.3648 - val_loss: 3.2522 - val_masked_accuracy: 0.3601\n",
            "Epoch 53/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2106 - masked_accuracy: 0.3624\n",
            "\n",
            "Generated_text: a dog running through the grass, \t f_score: 0.05112920100083274\n",
            "Generated_text: a small girl in a blue shirt and yellow shorts walks on a grassy field, \t f_score: 0.4137931034482759\n",
            "Generated_text: a little girl in a field of grass, \t f_score: 0.3032653298563167\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 3.2106 - masked_accuracy: 0.3624 - val_loss: 3.1763 - val_masked_accuracy: 0.3737\n",
            "Epoch 54/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.2078 - masked_accuracy: 0.3649\n",
            "\n",
            "Generated_text: a woman in a blue shirt and white shirt is walking by a dog, \t f_score: 0.35714285714285726\n",
            "Generated_text: a boy plays in a grassy field, \t f_score: 0.1882393740025864\n",
            "Generated_text: a woman in a black dress and a white dog is running, \t f_score: 0.3478260869565218\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.2078 - masked_accuracy: 0.3649 - val_loss: 3.1472 - val_masked_accuracy: 0.3739\n",
            "Epoch 55/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1959 - masked_accuracy: 0.3643\n",
            "\n",
            "Generated_text: a woman is sitting in a grassy field with a dog, \t f_score: 0.2727272727272727\n",
            "Generated_text: a girl in a green shirt and a brown dog runs through grass, \t f_score: 0.34306602427611943\n",
            "Generated_text: a small dog runs on a field, \t f_score: 0.15459210301798523\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 3.1959 - masked_accuracy: 0.3643 - val_loss: 3.1752 - val_masked_accuracy: 0.3706\n",
            "Epoch 56/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1718 - masked_accuracy: 0.3673\n",
            "\n",
            "Generated_text: a dog has a frisbee in the grass, \t f_score: 0.2170387196182017\n",
            "Generated_text: a little girl is jumping in the grass, \t f_score: 0.18195919791379003\n",
            "Generated_text: a dog with a white dog runs in the grass, \t f_score: 0.2585249765817027\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 3.1718 - masked_accuracy: 0.3673 - val_loss: 3.2220 - val_masked_accuracy: 0.3636\n",
            "Epoch 57/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1721 - masked_accuracy: 0.3676\n",
            "\n",
            "Generated_text: a little girl in a black shirt playing in the grass, \t f_score: 0.4263282165502494\n",
            "Generated_text: a small dog is running through the grass, \t f_score: 0.08588482777109359\n",
            "Generated_text: a group of young people sitting in grass with a green grass, \t f_score: 0.3255698941886978\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 3.1721 - masked_accuracy: 0.3676 - val_loss: 3.1715 - val_masked_accuracy: 0.3751\n",
            "Epoch 58/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1746 - masked_accuracy: 0.3687\n",
            "\n",
            "Generated_text: a dog running through a field of grass, \t f_score: 0.18195919791379003\n",
            "Generated_text: a little girl in a grassy field, \t f_score: 0.2102168235265385\n",
            "Generated_text: a dog runs through the grass, \t f_score: 0.05112920100083274\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 3.1746 - masked_accuracy: 0.3687 - val_loss: 3.1945 - val_masked_accuracy: 0.3693\n",
            "Epoch 59/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1587 - masked_accuracy: 0.3656\n",
            "\n",
            "Generated_text: a little girl wearing a red shirt and white dress is walking on a grassy field, \t f_score: 0.4\n",
            "Generated_text: a young girl with a black and white dog on the grass, \t f_score: 0.3333333333333333\n",
            "Generated_text: a young girl is jumping in the grass, \t f_score: 0.214712069427734\n",
            "100/100 [==============================] - 28s 277ms/step - loss: 3.1587 - masked_accuracy: 0.3656 - val_loss: 3.1287 - val_masked_accuracy: 0.3769\n",
            "Epoch 60/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1568 - masked_accuracy: 0.3705\n",
            "\n",
            "Generated_text: a dog is running through a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog is running through the grass, \t f_score: 0.07007227450884616\n",
            "Generated_text: a dog running through a grassy area, \t f_score: 0.14014454901769233\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 3.1568 - masked_accuracy: 0.3705 - val_loss: 3.1178 - val_masked_accuracy: 0.3770\n",
            "Epoch 61/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1736 - masked_accuracy: 0.3629\n",
            "\n",
            "Generated_text: a little girl in a pink shirt and white dog is playing in the grass, \t f_score: 0.5517241379310344\n",
            "Generated_text: a dog is running across a field, \t f_score: 0.12549291600172427\n",
            "Generated_text: a young girl standing in the air, \t f_score: 0.14014454901769233\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 3.1736 - masked_accuracy: 0.3629 - val_loss: 3.1187 - val_masked_accuracy: 0.3743\n",
            "Epoch 62/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1493 - masked_accuracy: 0.3685\n",
            "\n",
            "Generated_text: a little girl is running through a grassy field, \t f_score: 0.272964308790015\n",
            "Generated_text: a little girl is running through a field, \t f_score: 0.24261226388505333\n",
            "Generated_text: a little girl in a white shirt is playing with the ball, \t f_score: 0.3906838730264372\n",
            "100/100 [==============================] - 28s 282ms/step - loss: 3.1493 - masked_accuracy: 0.3685 - val_loss: 3.1416 - val_masked_accuracy: 0.3760\n",
            "Epoch 63/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1868 - masked_accuracy: 0.3655\n",
            "\n",
            "Generated_text: a dog running in the grass, \t f_score: 0.10225840200166549\n",
            "Generated_text: a brown dog running through the grass, \t f_score: 0.06274645800086213\n",
            "Generated_text: a dog running through the field, \t f_score: 0.05112920100083274\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 3.1868 - masked_accuracy: 0.3655 - val_loss: 3.1279 - val_masked_accuracy: 0.3746\n",
            "Epoch 64/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1294 - masked_accuracy: 0.3696\n",
            "\n",
            "Generated_text: a young girl running through a field, \t f_score: 0.15459210301798523\n",
            "Generated_text: a little girl in a white shirt and white dog running in the grass, \t f_score: 0.5\n",
            "Generated_text: a girl in a black shirt is running in the grass holding a stick in the background, \t f_score: 0.45161290322580644\n",
            "100/100 [==============================] - 29s 290ms/step - loss: 3.1294 - masked_accuracy: 0.3696 - val_loss: 3.1029 - val_masked_accuracy: 0.3793\n",
            "Epoch 65/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1066 - masked_accuracy: 0.3737\n",
            "\n",
            "Generated_text: two dogs run through the field, \t f_score: 0\n",
            "Generated_text: a small dog is running through a grassy field, \t f_score: 0.16014748058336156\n",
            "Generated_text: two little girls are playing in the field, \t f_score: 0.08588482777109359\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 3.1066 - masked_accuracy: 0.3737 - val_loss: 3.1200 - val_masked_accuracy: 0.3747\n",
            "Epoch 66/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1267 - masked_accuracy: 0.3657\n",
            "\n",
            "Generated_text: a young girl in a white shirt and red pants running through the grass, \t f_score: 0.42857142857142855\n",
            "Generated_text: a little boy in a field with a dog on the grass, \t f_score: 0.3333333333333333\n",
            "Generated_text: a little girl in a brown shirt with a dog and a small dog runs through a field, \t f_score: 0.39999999999999997\n",
            "100/100 [==============================] - 29s 295ms/step - loss: 3.1267 - masked_accuracy: 0.3657 - val_loss: 3.0849 - val_masked_accuracy: 0.3759\n",
            "Epoch 67/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1243 - masked_accuracy: 0.3697\n",
            "\n",
            "Generated_text: a little girl with a brown and white dog is walking in the grass, \t f_score: 0.35714285714285726\n",
            "Generated_text: a dog runs on a grassy field, \t f_score: 0.15459210301798523\n",
            "Generated_text: a dog running on a grassy field, \t f_score: 0.15459210301798523\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 3.1243 - masked_accuracy: 0.3697 - val_loss: 3.0547 - val_masked_accuracy: 0.3807\n",
            "Epoch 68/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1005 - masked_accuracy: 0.3696\n",
            "\n",
            "Generated_text: a little girl in a brown shirt is running in the grass, \t f_score: 0.45579785186417676\n",
            "Generated_text: a dog is running through the grass, \t f_score: 0.07007227450884616\n",
            "Generated_text: a little girl in a purple shirt is playing with a toy, \t f_score: 0.3906838730264372\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 3.1005 - masked_accuracy: 0.3696 - val_loss: 3.1123 - val_masked_accuracy: 0.3743\n",
            "Epoch 69/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1092 - masked_accuracy: 0.3702\n",
            "\n",
            "Generated_text: a dog is running in the grass, \t f_score: 0.12549291600172427\n",
            "Generated_text: a little girl is running in a field, \t f_score: 0.24261226388505333\n",
            "Generated_text: a little girl with a brown dog is on a grassy field, \t f_score: 0.4166666666666667\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 3.1092 - masked_accuracy: 0.3702 - val_loss: 3.0951 - val_masked_accuracy: 0.3745\n",
            "Epoch 70/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1117 - masked_accuracy: 0.3707\n",
            "\n",
            "Generated_text: two dogs are running in the grass, \t f_score: 0\n",
            "Generated_text: a dog runs through the grass, \t f_score: 0.05112920100083274\n",
            "Generated_text: a young girl in a field with a white hair and white dog on a grassy field, \t f_score: 0.4117647058823529\n",
            "100/100 [==============================] - 28s 283ms/step - loss: 3.1117 - masked_accuracy: 0.3707 - val_loss: 3.1170 - val_masked_accuracy: 0.3730\n",
            "Epoch 71/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.0865 - masked_accuracy: 0.3751\n",
            "\n",
            "Generated_text: a little girl is playing with a ball in the grass, \t f_score: 0.3176002491416565\n",
            "Generated_text: a little girl standing in the grass, \t f_score: 0.15459210301798523\n",
            "Generated_text: a dog runs with a ball in the grass, \t f_score: 0.24022122087504233\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 3.0865 - masked_accuracy: 0.3751 - val_loss: 3.1532 - val_masked_accuracy: 0.3705\n",
            "Epoch 72/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1010 - masked_accuracy: 0.3708\n",
            "\n",
            "Generated_text: a dog runs through a yard, \t f_score: 0.10225840200166549\n",
            "Generated_text: a dog is running along a path, \t f_score: 0.12549291600172427\n",
            "Generated_text: a dog jumping to catch a ball, \t f_score: 0.12549291600172427\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 3.1010 - masked_accuracy: 0.3708 - val_loss: 3.1298 - val_masked_accuracy: 0.3751\n",
            "Epoch 73/150\n",
            "100/100 [==============================] - ETA: 0s - loss: 3.1086 - masked_accuracy: 0.3700\n",
            "\n",
            "Generated_text: two children stand in the grass, \t f_score: 0\n",
            "Generated_text: a dog running in a field, \t f_score: 0.1533876030024982\n",
            "Generated_text: a small dog running through the grass, \t f_score: 0.06274645800086213\n",
            "100/100 [==============================] - 27s 269ms/step - loss: 3.1086 - masked_accuracy: 0.3700 - val_loss: 3.1131 - val_masked_accuracy: 0.3713\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "captioner_model.save('/content/drive/MyDrive/model/transformer_37.h5')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "BY04ouQLz50E",
        "outputId": "bc4d2a0e-8c91-467f-c20f-36df09629ae5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-2b6a2a778217>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcaptioner_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/model/transformer_37.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/saving/legacy/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msequential\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         ):\n\u001b[0;32m--> 154\u001b[0;31m             raise NotImplementedError(\n\u001b[0m\u001b[1;32m    155\u001b[0m                 \u001b[0;34m\"Saving the model to HDF5 format requires the model to be a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m                 \u001b[0;34m\"Functional model or a Sequential model. It does not work for \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Saving the model to HDF5 format requires the model to be a Functional model or a Sequential model. It does not work for subclassed models, because such models are defined via the body of a Python method, which isn't safely serializable. Consider saving to the Tensorflow SavedModel format (by setting save_format=\"tf\") or using `save_weights`."
          ]
        }
      ]
    }
  ]
}
